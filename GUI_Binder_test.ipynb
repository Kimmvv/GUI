{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressing-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#                                      Libs\n",
    "################################################################################################\n",
    "#Import best libraries ever made\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Panel\n",
    "import param\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "import panel.widgets as pnw\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "#Machine learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import random\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import scipy.stats\n",
    "\n",
    "#warnings - To do: correct warnings instead of suppressinng\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "################################################################################################\n",
    "#                                      run ml\n",
    "################################################################################################\n",
    "def ml(dataframe,obstype):    \n",
    "    numrepeats=5                                                                   # number of times to repeat training to test stabilty of results\n",
    "    regressionmodel=1                                                              # 0=regression tree, 1=gradient boosting, 2=random forest\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    max_depth=10                                                                   # maximum number of levels of tree\n",
    "    min_samples_leaf=2                                                             # splits per node\n",
    "    importancethreshold=0  \n",
    "\n",
    "    data3 = dataframe[:,5:]                                                           \n",
    "\n",
    "    rmse_all_train_wrpt = np.zeros((numrepeats,5))\n",
    "    rmse_all_test_wrpt = np.zeros((numrepeats,5))\n",
    "    R2_all_train_wrpt = np.zeros((numrepeats,5))\n",
    "    R2_all_test_wrpt = np.zeros((numrepeats,5))\n",
    "    importance_all_wrpt = np.zeros((numrepeats,5,np.shape(obstype)[0]))\n",
    "\n",
    "    for rpt in np.arange(numrepeats):\n",
    "        #print()\n",
    "        #print('repeat ',rpt)\n",
    "        for trgt in np.arange(5):\n",
    "            trgt_list = [int(trgt)]\n",
    "            #print('target ',trgt)\n",
    "\n",
    "            data2 = dataframe[:,:5]                                                           # EC_A, Thick_A, EC_B, Thick_B and EC_C\n",
    "            target=data2[:,trgt_list]                                                       # define specific target to predict and data to consider\n",
    "\n",
    "            if np.ndim(target)==1:                                                          # do some gymnastics to concatentate features and targets allowing for only a single target\n",
    "                addcols=1\n",
    "            else:\n",
    "                addcols=np.shape(target)[1]\n",
    "            data=np.zeros((np.shape(data3)[0],np.shape(data3)[1]+addcols))\n",
    "            data[:,:-addcols]=data3\n",
    "            data[:,-addcols:]=target\n",
    "\n",
    "            Predictions_use=data[:,np.shape(data)[1]-addcols:]                                                   # normalize target for ML analysis and save values to recover unnormalized values later\n",
    "            Predictions_usemean=np.mean(Predictions_use,axis=0)\n",
    "            Predictions_userange=np.max(Predictions_use,axis=0)-np.min(Predictions_use,axis=0)\n",
    "            Predictions_usemin=np.min(Predictions_use,axis=0)\n",
    "            Predictions_usestd=np.std(Predictions_use,axis=0)    \n",
    "            Predictions_use_norm = min_max_scaler.fit_transform(Predictions_use)           # normalizing flux DOES appear to be necessary, have to remember to un-normalize for later plots\n",
    "\n",
    "\n",
    "            #data2frame=np.hstack((data[:,:-1],Predictions_use_norm))                       # replace targets with normalized targets\n",
    "            data2frame = data.copy()\n",
    "            data2frame[:,np.shape(data)[1]-addcols:] = Predictions_use_norm\n",
    "\n",
    "\n",
    "            fract_train=0.7                                                                # define fraction of data to use for training\n",
    "            numtrain=int(fract_train*np.shape(data)[0])                                    # find number of training points\n",
    "            train_t=np.sort(random.sample(range(np.shape(data)[0]), numtrain))             # find times of training points\n",
    "            test_t=np.arange(np.shape(data)[0])                                            # find times of testing points\n",
    "            test_t = [i for i in test_t if i not in train_t]\n",
    "\n",
    "            training_data=data2frame[train_t,:]                                            # extract training data \n",
    "            testing_data=data2frame[test_t,:]                                              # extract testing data \n",
    "\n",
    "            if regressionmodel==0:                                                         # run machine learning analysis\n",
    "                regression_model = DecisionTreeRegressor(criterion=\"mse\",max_depth=max_depth, min_samples_leaf=min_samples_leaf)                      # MSE == varince is spliting criteria, minimum instances per leaf = 5\n",
    "                regression_model.fit(training_data[:,:-addcols],training_data[:,np.shape(data)[1]-addcols:])\n",
    "            elif regressionmodel==1:    \n",
    "                regression_model = ensemble.GradientBoostingRegressor(criterion=\"mse\",max_depth=max_depth, min_samples_leaf=min_samples_leaf)                      # MSE == varince is spliting criteria, minimum instances per leaf = 5\n",
    "                regression_model.fit(training_data[:,:-addcols],training_data[:,np.shape(data)[1]-addcols:])\n",
    "            else:    \n",
    "                regression_model = ensemble.RandomForestRegressor(criterion=\"mse\",max_depth=max_depth, min_samples_leaf=min_samples_leaf)                      # MSE == varince is spliting criteria, minimum instances per leaf = 5\n",
    "                regression_model.fit(training_data[:,:-addcols],training_data[:,np.shape(data)[1]-addcols:])\n",
    "\n",
    "            predicted_train = regression_model.predict(training_data[:,:-addcols])          # calculate predictions for training\n",
    "            predicted_train = predicted_train*Predictions_userange[0]+Predictions_usemin[0] # un-normalize predictions for training\n",
    "            true_train=Predictions_use[train_t]                                             # store correct target values for training\n",
    "            predicted = regression_model.predict(testing_data[:,:-addcols])                 # calculate predictions for testing\n",
    "            predicted = predicted*Predictions_userange[0]+Predictions_usemin[0]             # un-normalize predictions for testing\n",
    "            true=Predictions_use[test_t]                                                    # store correct target values for testing\n",
    "\n",
    "            importance = regression_model.feature_importances_                              # find feature importance values\n",
    "\n",
    "            slope, intercept, r_value_train, p_value, std_err = scipy.stats.linregress(np.squeeze(true_train), predicted_train)    \n",
    "            R2_train=r_value_train**2\n",
    "            rmse_train = sqrt(mean_squared_error(np.squeeze(true_train), predicted_train))\n",
    "\n",
    "            slope, intercept, r_value_test, p_value, std_err = scipy.stats.linregress(np.squeeze(true), predicted)    \n",
    "            R2_test=r_value_test**2\n",
    "            rmse_test = sqrt(mean_squared_error(np.squeeze(true), predicted))\n",
    "\n",
    "            rmse_all_train_wrpt[rpt,trgt]=rmse_train \n",
    "            rmse_all_test_wrpt[rpt,trgt]=rmse_test\n",
    "            R2_all_train_wrpt[rpt,trgt]=R2_train\n",
    "            R2_all_test_wrpt[rpt,trgt]=R2_test\n",
    "            importance_all_wrpt[rpt,trgt,:]=importance\n",
    "\n",
    "    mean_rmse_all_train  =np.mean(rmse_all_train_wrpt,axis=0)\n",
    "    mean_rmse_all_test   =np.mean(rmse_all_test_wrpt,axis=0)    \n",
    "    mean_R2_all_train    =np.mean(R2_all_train_wrpt,axis=0)\n",
    "    mean_R2_all_test     =np.mean(R2_all_test_wrpt,axis=0)\n",
    "    mean_importance_all  =np.mean(importance_all_wrpt,axis=0)\n",
    "    var_importance_all   =np.var(importance_all_wrpt,axis=0)\n",
    "    \n",
    "    mrat = [mean_rmse_all_test[0]/99,\n",
    "            mean_rmse_all_test[1]/1.45,\n",
    "            mean_rmse_all_test[2]/99,\n",
    "            mean_rmse_all_test[3]/1.9,\n",
    "            mean_rmse_all_test[4]/99]\n",
    "    \n",
    "    #col = ['HCP_1.0_0.1', 'HCP_1.0_0.3', 'HCP_1.0_0.5','HCP_2.5_0.1', 'HCP_2.5_0.3', 'HCP_2.5_0.5','HCP_4.0_0.1', 'HCP_4.0_0.3', 'HCP_4.0_0.5',           \n",
    "    #       'VCP_1.0_0.1', 'VCP_1.0_0.3', 'VCP_1.0_0.5','VCP_2.5_0.1', 'VCP_2.5_0.3', 'VCP_2.5_0.5','VCP_4.0_0.1', 'VCP_4.0_0.3', 'VCP_4.0_0.5',       \n",
    "    #       'PRP_1.0_0.1', 'PRP_1.0_0.3', 'PRP_1.0_0.5','PRP_2.5_0.1', 'PRP_2.5_0.3', 'PRP_2.5_0.5','PRP_4.0_0.1', 'PRP_4.0_0.3', 'PRP_4.0_0.5']\n",
    "\n",
    "    mia = pd.DataFrame(mean_importance_all,columns = obstype)\n",
    "    #print('ml done')\n",
    "    return mrat,mia\n",
    "\n",
    "################################################################################################\n",
    "#                                   Emi hist \n",
    "################################################################################################\n",
    "\n",
    "def emi_hist(emi_data):   \n",
    "    #Titles, column numbers and colours\n",
    "    titles = [['HCP1', 'HCP2.5', 'HCP4'], ['VCP1', 'VCP2.5', 'VCP4'],['PRP1', 'PRP2.5', 'PRP4']]\n",
    "    num = [[5,8,11],[14,17,20],[23,24,27]]\n",
    "    colour = [\"b\",\"y\",\"r\"]\n",
    "    \n",
    "    #Plot\n",
    "    fig, axes = plt.subplots(nrows = 3, ncols = 3,  sharex=True, sharey=True)\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, cell in enumerate(row):\n",
    "                    if num[i][j] == 5:\n",
    "                        legend = [\"0.1m\",\"0.3m\",\"0.5m\"]\n",
    "                    else:\n",
    "                        legend='_nolegend_'\n",
    "                    cell.hist([emi_data[emi_data.columns[num[i][j]]],emi_data[emi_data.columns[num[i][j]+1]],emi_data[emi_data.columns[num[i][j]+2]]]\n",
    "                              ,bins='auto', alpha=1, rwidth=0.85, label=legend, color=colour, histtype='step')\n",
    "                    cell.set_title(titles[i][j])\n",
    "                    if i == len(axes) - 1:\n",
    "                        cell.set_xlabel(\"EC$_a$ [mS/m]\".format(j + 1))\n",
    "                    if j == 0:\n",
    "                        cell.set_ylabel(\"Frequency\".format(i + 1))\n",
    "\n",
    "    fig.legend(loc='lower center', bbox_to_anchor=(0.5, 0.0),fancybox=True, shadow=True, ncol=3,title = \"Instrument height\")\n",
    "    plt.tight_layout(rect=[0,0.1,0.99,1])\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "################################################################################################\n",
    "#                                   feature importance \n",
    "################################################################################################\n",
    "\n",
    "def full_feat_imp():\n",
    "    full = pd.read_csv('data/Mean_imp_ThickA_full.csv', index_col=0,sep=',')\n",
    "    col = ['HCP_1.0_0.1', 'HCP_1.0_0.3', 'HCP_1.0_0.5',\n",
    "           'HCP_2.5_0.1', 'HCP_2.5_0.3', 'HCP_2.5_0.5',\n",
    "           'HCP_4.0_0.1', 'HCP_4.0_0.3', 'HCP_4.0_0.5',\n",
    "\n",
    "           'VCP_1.0_0.1', 'VCP_1.0_0.3', 'VCP_1.0_0.5',\n",
    "           'VCP_2.5_0.1', 'VCP_2.5_0.3', 'VCP_2.5_0.5',\n",
    "           'VCP_4.0_0.1', 'VCP_4.0_0.3', 'VCP_4.0_0.5',\n",
    "\n",
    "           'PRP_1.0_0.1', 'PRP_1.0_0.3', 'PRP_1.0_0.5',\n",
    "           'PRP_2.5_0.1', 'PRP_2.5_0.3', 'PRP_2.5_0.5',\n",
    "           'PRP_4.0_0.1', 'PRP_4.0_0.3', 'PRP_4.0_0.5']\n",
    "\n",
    "    df = pd.DataFrame(columns=col)\n",
    "    cfg = df.columns\n",
    "\n",
    "    param = [0,1,2,3,4]\n",
    "    par_name = ['ECA', 'ThickA', 'ECB', 'ThickB', 'ECC']\n",
    "    idx = ['full','cen','sl','sh']\n",
    "\n",
    "    fig = plt.figure(figsize=(12.8,3.8))\n",
    "    size=7\n",
    "    spec = gridspec.GridSpec(ncols=5, nrows=1, wspace = 11.35)\n",
    "    axs = []\n",
    "\n",
    "    for ipar in param:\n",
    "        par = ipar #0=ECA, 1=ThickA, 2=ECB, 3=ThickB, 4=ECC\n",
    "\n",
    "        f =  full.iloc[par,:].values    \n",
    "        ECA_imp = pd.DataFrame([f],columns = cfg, index = idx) #only use the full range (f) for this plot\n",
    "        mean = ECA_imp.mean() #Mean of each column\n",
    "\n",
    "        p_val = 8      #Values to plot seperately\n",
    "        o_val = 27-p_val #Values to aggregate into \"others\" white category\n",
    "        # sum of p_val & o_val must be 27\n",
    "\n",
    "        if p_val + o_val != 27:\n",
    "            print(\"Values are not equal 27\")\n",
    "            exit(0)\n",
    "\n",
    "        most_imp = np.argsort(-np.asarray(mean))[:p_val] # The # most important feats\n",
    "        other = cfg[np.argsort(-np.asarray(mean))[-o_val:]] #Other bin\n",
    "\n",
    "        #Re-sort the most imp feats based on the order they appear originally so the coil pos are next to each other \n",
    "        most_imp_sort = np.sort(most_imp) \n",
    "\n",
    "        #Full\n",
    "        f_other_val = f[np.argsort(-np.asarray(mean))[-o_val:]].sum()\n",
    "        full_val = f[most_imp_sort]\n",
    "        full_val= np.append(full_val,f_other_val)\n",
    "\n",
    "        #Labels\n",
    "        label = list(cfg[most_imp_sort])\n",
    "        label.append('others')\n",
    "\n",
    "        ##################################################################################\n",
    "        #                       Custom colourmap                    \n",
    "        ##################################################################################\n",
    "        blue = cm.get_cmap('Blues',9)\n",
    "        red = cm.get_cmap('Reds',9)\n",
    "        green = cm.get_cmap('Greens',9)\n",
    "\n",
    "        low, mid, high = 7,5,2\n",
    "        white = (1.0, 1.0, 1.0, 1.0)\n",
    "        hatches = [ \"\" , \"//\" , \"O\" , \"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\",\"\" , \"//\" , \"O\",\"\" ]\n",
    "        clr = [blue(low),blue(low),blue(low),blue(mid),blue(mid),blue(mid),blue(high),blue(high),blue(high),\n",
    "               green(low),green(low),green(low),green(mid),green(mid),green(mid),green(high),green(high),green(high),\n",
    "               red(low),red(low),red(low),red(mid),red(mid),red(mid),red(high),red(high),red(high),\n",
    "               white]\n",
    "\n",
    "        newcolor =  []\n",
    "        for i in most_imp_sort:\n",
    "            newcolor.append(clr[i])\n",
    "        newcolor.append(white) #Other category is always white\n",
    "\n",
    "        newhatches = []\n",
    "        for j in most_imp_sort:\n",
    "            newhatches.append(hatches[j])\n",
    "        newhatches.append(\"\")\n",
    "\n",
    "        cmap = ListedColormap(newcolor,N=p_val)  \n",
    "        \n",
    "        ############################# With hatches ######################################\n",
    "        #fig1, f1_axes = plt.subplots(ncols=5, nrows=1, constrained_layout=True)\n",
    "\n",
    "        #vals = [sh_val,sl_val,c_val,full_val]\n",
    "        vals = [full_val]\n",
    "        size = size\n",
    "        #radius = [1+size*2,1+size,1,1-size]\n",
    "        radius = [1+size*2]\n",
    "\n",
    "        axs.append(fig.add_subplot(spec[0, ipar]))\n",
    "\n",
    "        for ival,ir in zip(vals,radius):\n",
    "            piechart = axs[-1].pie(ival, radius = ir, wedgeprops=dict(edgecolor='k'), colors=newcolor)\n",
    "            for i in range(len(piechart[0])):\n",
    "                piechart[0][i].set_hatch(newhatches[(i)%len(newhatches)])\n",
    "\n",
    "        #axs[-1].text(-0.1,0.0,par_name[ipar])\n",
    "        #ax.legend(loc='upper left', labels=label,prop={'size': 12}, bbox_to_anchor=(-0.1, 1), bbox_transform=fig.transFigure)\n",
    "        axs[-1].set_title(par_name[ipar],y=6.5)\n",
    "        #plt.show()\n",
    "\n",
    "    #axs.append(fig.add_subplot(spec[0, 5]))\n",
    "    patches = []\n",
    "    conf = list(cfg)\n",
    "    conf.append('others')\n",
    "    for ic,icfg,ih in zip(clr,conf,hatches):\n",
    "        patches.append(mpatches.Patch(facecolor=ic, hatch=ih, label=icfg, edgecolor='k'))\n",
    "\n",
    "    #plt.legend(handles=patches,ncol=7, bbox_to_anchor=(1.25, -0.2))#,prop={'size': 12}, bbox_transform = fig.transFigure)    \n",
    "    fig.suptitle('Feature importance for current setup', fontsize = 18, x = 0.5, y = 0.96)\n",
    "    #plt.tight_layout(rect=[0,0.1,0.99,0.1])\n",
    "    plt.close()  \n",
    "    return fig\n",
    "\n",
    "#full_feat_imp()\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#                                 update feature importance \n",
    "################################################################################################\n",
    "def upd_feat_imp(df):\n",
    "    full = df #pd.read_csv('data/Mean_imp_ThickA_full.csv', index_col=0,sep=',')\n",
    "   \n",
    "    cfg = full.columns\n",
    "\n",
    "    param = [0,1,2,3,4]\n",
    "    par_name = ['ECA', 'ThickA', 'ECB', 'ThickB', 'ECC']\n",
    "    idx = ['full','cen','sl','sh']\n",
    "\n",
    "    fig = plt.figure(figsize=(12.8,3.8))\n",
    "    size=7\n",
    "    spec = gridspec.GridSpec(ncols=5, nrows=1, wspace = 11.35)\n",
    "    axs = []\n",
    "\n",
    "    for ipar in param:\n",
    "        par = ipar #0=ECA, 1=ThickA, 2=ECB, 3=ThickB, 4=ECC\n",
    "\n",
    "        f =  full.iloc[par,:].values    \n",
    "        ECA_imp = pd.DataFrame([f],columns = cfg, index = idx) #only use the full range (f) for this plot\n",
    "        mean = ECA_imp.mean() #Mean of each column\n",
    "\n",
    "        p_val = 8      #Values to plot seperately\n",
    "        o_val = len(cfg)-p_val #Values to aggregate into \"others\" white category\n",
    "        # sum of p_val & o_val must be 27\n",
    "\n",
    "        if p_val + o_val != len(cfg):\n",
    "            print(\"Values are not equal column names\")\n",
    "            exit(0)\n",
    "\n",
    "        most_imp = np.argsort(-np.asarray(mean))[:p_val] # The # most important feats\n",
    "        other = cfg[np.argsort(-np.asarray(mean))[-o_val:]] #Other bin\n",
    "\n",
    "        #Re-sort the most imp feats based on the order they appear originally so the coil pos are next to each other \n",
    "        most_imp_sort = np.sort(most_imp) \n",
    "\n",
    "        #Full\n",
    "        f_other_val = f[np.argsort(-np.asarray(mean))[-o_val:]].sum()\n",
    "        full_val = f[most_imp_sort]\n",
    "        full_val= np.append(full_val,f_other_val)\n",
    "\n",
    "        #Labels\n",
    "        label = list(cfg[most_imp_sort])\n",
    "        label.append('others')\n",
    "\n",
    "        ##################################################################################\n",
    "        #                       Custom colourmap                    \n",
    "        ##################################################################################\n",
    "        blue = cm.get_cmap('Blues',9)\n",
    "        red = cm.get_cmap('Reds',9)\n",
    "        green = cm.get_cmap('Greens',9)\n",
    "\n",
    "        low, mid, high = 7,5,2\n",
    "        white = (1.0, 1.0, 1.0, 1.0)\n",
    "        hatches = [ \"\" , \"//\" , \"O\" , \"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\" ,\"\" , \"//\" , \"O\",\"\" , \"//\" , \"O\",\"\" ]\n",
    "        clr = [blue(low),blue(low),blue(low),blue(mid),blue(mid),blue(mid),blue(high),blue(high),blue(high),\n",
    "               green(low),green(low),green(low),green(mid),green(mid),green(mid),green(high),green(high),green(high),\n",
    "               red(low),red(low),red(low),red(mid),red(mid),red(mid),red(high),red(high),red(high),\n",
    "               white]\n",
    "\n",
    "        newcolor =  []\n",
    "        for i in most_imp_sort:\n",
    "            newcolor.append(clr[i])\n",
    "        newcolor.append(white) #Other category is always white\n",
    "\n",
    "        newhatches = []\n",
    "        for j in most_imp_sort:\n",
    "            newhatches.append(hatches[j])\n",
    "        newhatches.append(\"\")\n",
    "\n",
    "        cmap = ListedColormap(newcolor,N=p_val)  \n",
    "        \n",
    "        ############################# With hatches ######################################\n",
    "        #fig1, f1_axes = plt.subplots(ncols=5, nrows=1, constrained_layout=True)\n",
    "\n",
    "        #vals = [sh_val,sl_val,c_val,full_val]\n",
    "        vals = [full_val]\n",
    "        size = size\n",
    "        #radius = [1+size*2,1+size,1,1-size]\n",
    "        radius = [1+size*2]\n",
    "\n",
    "        axs.append(fig.add_subplot(spec[0, ipar]))\n",
    "\n",
    "        for ival,ir in zip(vals,radius):\n",
    "            piechart = axs[-1].pie(ival, radius = ir, wedgeprops=dict(edgecolor='k'), colors=newcolor)\n",
    "            for i in range(len(piechart[0])):\n",
    "                piechart[0][i].set_hatch(newhatches[(i)%len(newhatches)])\n",
    "\n",
    "        #axs[-1].text(-0.1,0.0,par_name[ipar])\n",
    "        #ax.legend(loc='upper left', labels=label,prop={'size': 12}, bbox_to_anchor=(-0.1, 1), bbox_transform=fig.transFigure)\n",
    "        axs[-1].set_title(par_name[ipar],y=6.5)\n",
    "        #plt.show()\n",
    "\n",
    "    #axs.append(fig.add_subplot(spec[0, 5]))\n",
    "    patches = []\n",
    "    conf = list(cfg)\n",
    "    conf.append('others')\n",
    "    for ic,icfg,ih in zip(clr,conf,hatches):\n",
    "        patches.append(mpatches.Patch(facecolor=ic, hatch=ih, label=icfg, edgecolor='k'))\n",
    "\n",
    "    #plt.legend(handles=patches,ncol=7, bbox_to_anchor=(1.25, -0.2))#,prop={'size': 12}, bbox_transform = fig.transFigure)    \n",
    "    fig.suptitle('Feature importance for current setup', fontsize = 22, x = 0.5, y = 0.96)\n",
    "    #plt.tight_layout(rect=[0,0.1,0.99,0.1])\n",
    "    plt.close()  \n",
    "    return fig\n",
    "\n",
    "################################################################################################\n",
    "#                                  Panel app\n",
    "################################################################################################\n",
    "\n",
    "######## Create widgets ########\n",
    "#Button\n",
    "button  = pn.widgets.Button(name='Run ml with current setup')\n",
    "\n",
    "#Image\n",
    "png = pn.panel('data/Feat_imp_full.png', width=920)\n",
    "\n",
    "#Sliders (instrument parameters)\n",
    "eca     = pnw.RangeSlider(name='ECA [mS/m]', value=(1,100),    start=1,    end=100, step=11) \n",
    "thicka  = pnw.RangeSlider(name='ThickA [m]', value=(0.05,1.5), start=0.05, end=1.5, step=0.1611111111111111) \n",
    "ecb     = pnw.RangeSlider(name='ECB [mS/m]', value=(1,100),    start=1,    end=100, step=11) \n",
    "thickb  = pnw.RangeSlider(name='ThickB [m]', value=(0.05,2.0), start=0.1,  end=2.0, step=0.2111111111111111) \n",
    "ecc     = pnw.RangeSlider(name='ECC [mS/m]', value=(1,100),    start=1,    end=100, step=11) \n",
    "\n",
    "#Checkboxes (instrument parameters)\n",
    "max_width  = 110\n",
    "max_width2 = 30\n",
    "hcp     = pn.widgets.Checkbox(name='HCP', max_width=max_width, value=True)\n",
    "vcp     = pn.widgets.Checkbox(name='VCP', max_width=max_width, value=True)\n",
    "prp     = pn.widgets.Checkbox(name='PRP', max_width=max_width2,value=True)\n",
    "\n",
    "one     = pn.widgets.Checkbox(name='1.0m', max_width=max_width, value=True)\n",
    "two     = pn.widgets.Checkbox(name='2.5m', max_width=max_width, value=True)\n",
    "four    = pn.widgets.Checkbox(name='4.0m', max_width=max_width2,value=True)\n",
    "\n",
    "ten     = pn.widgets.Checkbox(name='0.1m', max_width=max_width, value=True)\n",
    "thirty  = pn.widgets.Checkbox(name='0.3m', max_width=max_width, value=True)\n",
    "fifty   = pn.widgets.Checkbox(name='0.5m', max_width=max_width2,value=True)\n",
    "\n",
    "#Text\n",
    "row_count   = pn.widgets.TextInput(name='Rows in EMI dataframe', value='100000')\n",
    "run_timer   = pn.widgets.TextInput(name='Estimated run time [min]', value='70')\n",
    "cpos        = \"\\n#### Coil position\"\n",
    "csep        = \"\\n#### Coil separation\"\n",
    "insh        = \"\\n#### Instrument height\"\n",
    "text_widget = pn.Column(\"<br>\\n#### Parameters\", eca, thicka, ecb, thickb, ecc, row_count,run_timer,cpos,pn.Row(hcp,vcp,prp),csep,pn.Row(one,two,four),insh,pn.Row(ten,thirty,fifty))\n",
    "\n",
    "###### Create functions #######\n",
    "#Emi 3x3 histograms\n",
    "def restrict_emi(eca,thicka,ecb,thickb,ecc):\n",
    "    #Read EMImatrix from csv\n",
    "    emi_data = pd.read_csv('data/EMImatrix.csv', index_col=0, sep=',')   \n",
    "            \n",
    "    #Constrain it!\n",
    "    emi_data = emi_data[emi_data['ECA']    >= eca[0]]\n",
    "    emi_data = emi_data[emi_data['ECA']    <= eca[1]]\n",
    "    \n",
    "    emi_data = emi_data[emi_data['ThickA'] >= thicka[0]]\n",
    "    emi_data = emi_data[emi_data['ThickA'] <= thicka[1]]\n",
    "\n",
    "    emi_data = emi_data[emi_data['ECB']    >= ecb[0]]\n",
    "    emi_data = emi_data[emi_data['ECB']    <= ecb[1]]\n",
    "    \n",
    "    emi_data = emi_data[emi_data['ThickB'] >= thickb[0]]\n",
    "    emi_data = emi_data[emi_data['ThickB'] <= thickb[1]]\n",
    "    \n",
    "    emi_data = emi_data[emi_data['ECC']    >= ecc[0]]\n",
    "    emi_data = emi_data[emi_data['ECC']    <= ecc[1]]\n",
    "    \n",
    "    l = len(emi_data) #rows left in the frame\n",
    "\n",
    "    return emi_data,l\n",
    "\n",
    "#Link restrict_emi to current slider value\n",
    "@pn.depends(eca.param.value,thicka.param.value,ecb.param.value,thickb.param.value,ecc.param.value)\n",
    "def restrict_emi_variables(eca,thicka,ecb,thickb,ecc):\n",
    "    emi = restrict_emi(eca,thicka,ecb,thickb,ecc)[0]\n",
    "    row_count.value = str(restrict_emi(eca,thicka,ecb,thickb,ecc)[1])\n",
    "    run_timer.value = str(0.0007 * restrict_emi(eca,thicka,ecb,thickb,ecc)[1] + 1.308)\n",
    "    return emi_hist(emi)\n",
    "\n",
    "def run_ml():\n",
    "    #Read EMImatrix from csv\n",
    "    temp_data = pd.read_csv('data/EMImatrix.csv', index_col=0, sep=',')\n",
    "    \n",
    "    ################## Constrain it! ###############\n",
    "    #Constrain based on coil position\n",
    "    if hcp.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), 'hcp') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "\n",
    "    if vcp.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), 'vcp') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "   \n",
    "    if prp.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), 'prp') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "\n",
    "    #Constrain based on coil separation\n",
    "    if one.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), '1.0') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "\n",
    "    if two.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), '2.5') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "   \n",
    "    if four.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), '4.0') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "     \n",
    "    #Constrain based on instrument height\n",
    "    if ten.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), '0.1') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "\n",
    "    if thirty.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), '0.3') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "   \n",
    "    if fifty.value == False:\n",
    "        m = np.core.defchararray.find(temp_data.columns.values.astype(str), '0.5') < 0\n",
    "        temp_data = pd.DataFrame(temp_data.values[:,m], temp_data.index, temp_data.columns[m])\n",
    "    \n",
    "    #Constrain based on soil parameters\n",
    "    temp_data = temp_data[temp_data['ECA']    >= eca.value[0]]\n",
    "    temp_data = temp_data[temp_data['ECA']    <= eca.value[1]]\n",
    "    \n",
    "    temp_data = temp_data[temp_data['ThickA'] >= thicka.value[0]]\n",
    "    temp_data = temp_data[temp_data['ThickA'] <= thicka.value[1]]\n",
    "\n",
    "    temp_data = temp_data[temp_data['ECB']    >= ecb.value[0]]\n",
    "    temp_data = temp_data[temp_data['ECB']    <= ecb.value[1]]\n",
    "    \n",
    "    temp_data = temp_data[temp_data['ThickB'] >= thickb.value[0]]\n",
    "    temp_data = temp_data[temp_data['ThickB'] <= thickb.value[1]]\n",
    "    \n",
    "    temp_data = temp_data[temp_data['ECC']    >= ecc.value[0]]\n",
    "    temp_data = temp_data[temp_data['ECC']    <= ecc.value[1]]\n",
    "\n",
    "    #Get observation type and convert dataframe to numpy array for easy ML consumption\n",
    "    obstype = temp_data.columns[5:].values\n",
    "    temp = temp_data.to_numpy()\n",
    "    \n",
    "    #Run ml on constrained\n",
    "    mrat,mia = ml(dataframe=temp,obstype=obstype)\n",
    "    \n",
    "    return mrat,mia\n",
    "\n",
    "#Initial figures\n",
    "def plot_arr():\n",
    "    param = ['ECA', 'ThickA', 'ECB', 'ThickB', 'ECC']    \n",
    "    nrmse_full = [7.3/100,0.28/1.45,18.9/100,0.49/1.9,1.5/100]\n",
    "    x = [1,2,3,4,5]\n",
    "\n",
    "    # Plot 1 rmse/r²\n",
    "    fig1= plt.figure() \n",
    "    plt.scatter(x,nrmse_full,label='Full range',marker='_',color='k',s=200)\n",
    "    plt.xticks(x,param)\n",
    "    plt.title('NRMSE')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.close()\n",
    "    \n",
    "    fig2 = full_feat_imp()\n",
    "    \n",
    "    return fig1,fig2\n",
    "\n",
    "#Update figure\n",
    "def plot_arr_2():\n",
    "    param = ['ECA', 'ThickA', 'ECB', 'ThickB', 'ECC']    \n",
    "    nrmse_full = [7.3/100,0.28/1.45,18.9/100,0.49/1.9,1.5/100]\n",
    "    x = [1,2,3,4,5]\n",
    "    mrat,mia = run_ml()\n",
    "\n",
    "    # Plot 1 rmse/r²\n",
    "    fig1= plt.figure() \n",
    "    plt.scatter(x,nrmse_full,label='Full range',marker='_',color='k',s=200)\n",
    "    plt.scatter(x,mrat,label='Custom range')\n",
    "    plt.xticks(x,param)\n",
    "    plt.title('NRMSE')\n",
    "    plt.xlabel('Parameter')\n",
    "    plt.ylabel('')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 3 Feature imp\n",
    "    fig2 = upd_feat_imp(mia)\n",
    "    \n",
    "    return fig1,fig2\n",
    "\n",
    "############ Layout #############\n",
    "layout = pn.Row( pn.Column(pn.Row(plot_arr()[0],restrict_emi_variables),                # RMSE & emi hist\n",
    "                   pn.Row(pn.Column(pn.Row(plot_arr()[1]),pn.Row(png) ))                # Button          \n",
    "                          )\n",
    "                 ,pn.Column(text_widget,button))                             # Right side text & sliders goes here\n",
    "\n",
    "########### Callback ############\n",
    "def update(event):\n",
    "    layout[0][0][0].object, layout[0][1][0][0][0].object = plot_arr_2()\n",
    "     \n",
    "# Update/replace the existing rendered component\n",
    "button.on_click(update)\n",
    "\n",
    "# Return panel object\n",
    "layout.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "! panel serve --show --port 5009 GUI_Binder_test.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
